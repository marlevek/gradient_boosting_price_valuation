{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com este dataset vamos avaliar preços de casas em Melbourne. Os valores estã expressos em Dolar Australiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando as bibliotecas que serão usadas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>68 Studley St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>Jellis</td>\n",
       "      <td>3/09/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra City Council</td>\n",
       "      <td>-37.8014</td>\n",
       "      <td>144.9958</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>3/12/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra City Council</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra City Council</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>18/659 Victoria St</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VB</td>\n",
       "      <td>Rounds</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra City Council</td>\n",
       "      <td>-37.8114</td>\n",
       "      <td>145.0116</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra City Council</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb             Address  Rooms Type      Price Method SellerG  \\\n",
       "0  Abbotsford       68 Studley St      2    h        NaN     SS  Jellis   \n",
       "1  Abbotsford        85 Turner St      2    h  1480000.0      S  Biggin   \n",
       "2  Abbotsford     25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
       "3  Abbotsford  18/659 Victoria St      3    u        NaN     VB  Rounds   \n",
       "4  Abbotsford        5 Charles St      3    h  1465000.0     SP  Biggin   \n",
       "\n",
       "        Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0  3/09/2016       2.5    3067.0  ...       1.0  1.0     126.0           NaN   \n",
       "1  3/12/2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n",
       "2  4/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n",
       "3  4/02/2016       2.5    3067.0  ...       2.0  1.0       0.0           NaN   \n",
       "4  4/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n",
       "\n",
       "   YearBuilt         CouncilArea Lattitude  Longtitude             Regionname  \\\n",
       "0        NaN  Yarra City Council  -37.8014    144.9958  Northern Metropolitan   \n",
       "1        NaN  Yarra City Council  -37.7996    144.9984  Northern Metropolitan   \n",
       "2     1900.0  Yarra City Council  -37.8079    144.9934  Northern Metropolitan   \n",
       "3        NaN  Yarra City Council  -37.8114    145.0116  Northern Metropolitan   \n",
       "4     1900.0  Yarra City Council  -37.8093    144.9944  Northern Metropolitan   \n",
       "\n",
       "  Propertycount  \n",
       "0        4019.0  \n",
       "1        4019.0  \n",
       "2        4019.0  \n",
       "3        4019.0  \n",
       "4        4019.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando o dataset\n",
    "df = pd.read_csv('Melbourne_housing_FULL.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Removendo colunas que não são necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Address']\n",
    "del df['Method']\n",
    "del df['SellerG']\n",
    "del df['Date']\n",
    "del df['Postcode']\n",
    "del df['Lattitude']\n",
    "del df['Longtitude']\n",
    "del df['Regionname']\n",
    "del df['Propertycount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb              0\n",
       "Rooms               0\n",
       "Type                0\n",
       "Price            7610\n",
       "Distance            1\n",
       "Bedroom2         8217\n",
       "Bathroom         8226\n",
       "Car              8728\n",
       "Landsize        11810\n",
       "BuildingArea    21115\n",
       "YearBuilt       19306\n",
       "CouncilArea         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando se há valores ausentes\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Removendo os valores ausentes. Como é um exercício vamos eliminar os valores ausentes para ser mais simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='any', subset=None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb          0\n",
       "Rooms           0\n",
       "Type            0\n",
       "Price           0\n",
       "Distance        0\n",
       "Bedroom2        0\n",
       "Bathroom        0\n",
       "Car             0\n",
       "Landsize        0\n",
       "BuildingArea    0\n",
       "YearBuilt       0\n",
       "CouncilArea     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Agora vamos converter as conlunas que contêm valores não numéricos usando a técnica 'one-hot-enconding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=['Suburb', 'CouncilArea', 'Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Setando as variáveis independentes com X e a variável dependente (Price) como y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os dados em dados de treino e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos selecionar o algoritmo e configurar os hiper-parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble.GradientBoostingRegressor(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=30,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=6,\n",
    "    max_features=0.6,\n",
    "   loss='huber'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicando os hiperparâmetros:\n",
    "<ul>\n",
    "<li>n_estimators: número de árvores de decisão</li>\n",
    "<li>learning_rate: controla a taxa na qual árvores de decisão adicionais influenciam a previsão geral.</li>\n",
    "<li>max_depth: define o máximo de camadas para cada árvore de decisão</li>\n",
    "<li>min_samples_split: o número mínimo requerido de amostras para executar uma nova divisão binária, para criar um novo ramo(branch)</li>\n",
    "<li>min_samples_leaf: número mínimo de amostras que deve aparecer em cada folha antes de um novo ramo ser implementado. Isso ajuda a atenuar o impacto de outliers e anomalias</li>\n",
    "<li>max_features: número total de características apresentadas ao modelo ao determinar a melhor divisão</li>\n",
    "<li>loss: calcula a taxa de erro do modelo. No caso, huber protege contra outliers e anomailias.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(loss='huber', max_depth=30, max_features=0.6,\n",
       "                          min_samples_leaf=6, min_samples_split=4,\n",
       "                          n_estimators=150)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustando o modelo\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando os Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar a função predict() para executar o modelo nos dados de treino e avaliar sua performance contra os dados reais (y_train). Faremos isso usando o erro médio absoluto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro médio absoluto dos dados de treinamento: 28081.11\n"
     ]
    }
   ],
   "source": [
    "mae_train = mean_absolute_error(y_train, model.predict(X_train))\n",
    "print(f'Erro médio absoluto dos dados de treinamento: {mae_train:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro médio absoluto dos dados de teste: 168490.65\n"
     ]
    }
   ],
   "source": [
    "# Usando o mesmo método anterior para os dados de teste\n",
    "mae_test = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(f'Erro médio absoluto dos dados de teste: {mae_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados: <br>1. nosso modelo de treinamento foi eficaz em prever o real valor das propriedades contidas nos dados de treino.<br>Pode parecer que $28081.11 seja uma grande quantia mas esse erro médio é baixo considerando que o range máximo do nosso conjunto de dados é $8 milhões.<br>2. A alta discrepância entre os erros de treinamento e de teste indica que há um overffiting. No nosso caso, esta diferença é exacerbada porque configuramos o modelo para fazer um overffit nos dados de treino, quando configuramos o max_depht = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OTIMIZAÇÃO DO MODELO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro ponto é modificar os hiperparâmetros.<br>Vamos começar ajustando max_depth = 5 e deixar os outros como estão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble.GradientBoostingRegressor(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=6,\n",
    "    max_features=0.6,\n",
    "    loss='huber'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(loss='huber', max_depth=5, max_features=0.6,\n",
       "                          min_samples_leaf=6, min_samples_split=4,\n",
       "                          n_estimators=150)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro médio absoluto dos dados de treinamento: 135904.92\n"
     ]
    }
   ],
   "source": [
    "# Erro médio absoluto dos dados de treinamento\n",
    "mae_train = mean_absolute_error(y_train, model.predict(X_train))\n",
    "print(f'Erro médio absoluto dos dados de treinamento: {mae_train:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos otimizar o modelo agora adicionando mais árvores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble.GradientBoostingRegressor(\n",
    "    n_estimators=250,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=6,\n",
    "    max_features=0.6,\n",
    "    loss='huber'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(loss='huber', max_depth=5, max_features=0.6,\n",
       "                          min_samples_leaf=6, min_samples_split=4,\n",
       "                          n_estimators=250)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro médio absoluto dos dados de treinamento: 123086.11\n",
      "Erro médio absoluto dos dados de teste: 163098.00\n"
     ]
    }
   ],
   "source": [
    "# Erros médios absolutos de treino e teste\n",
    "mae_train = mean_absolute_error(y_train, model.predict(X_train))\n",
    "print(f'Erro médio absoluto dos dados de treinamento: {mae_train:.2f}')\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(f'Erro médio absoluto dos dados de teste: {mae_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta segunda otimização reduziu a taxa do erro médio absoluto de treino em aproximadamente $11,000 e há uma pequena lacuna entre os resultados de treino e teste.<br>Essas duas otimizações servem para mostrar a importância de se compreender individualmente os hiperparâmetros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
